
%In this section, a collection of the earlier works related to our designed model is given. Two main related topics will be covered.\\
%\subsection{Models for reading comprehension}
%Previous work on question answering is abundantly based on end-to-end deep learning (DNN) models. They are usually equipped with two key techniques: (1) a recurrent or convolutional structure to capture dependencies of the sequential input, and (2) an attention module to fusion information from context and query. For example, \textbf{Bi-Directional Attention Flow network (BiDAF)} \cite{DBLP:conf/iclr/SeoKFH17} adopts LSTM and RNN to generate character and contextual embeddings and feed them to a flow-based attention module. \textbf{QANet} \cite{DBLP:journals/corr/abs-1804-09541} replaces recurrent structure with convolutions and self-attentions to achieve a faster training. \textbf{Attention-Sum (AS) Reader} \cite{DBLP:conf/acl/KadlecSBK16} uses two bidirectional GRU networks to encode context and query, and then \textit{pointer-sum attention} is used to aggregate information of repeated entities. \textbf{Gated-Attention (GA) Reader} \cite{DBLP:conf/acl/DhingraLYCS17} extends AS Reader by introducing a new aggregation scheme named \textit{gated attention} to mimic the multi-step comprehension process of human readers, and their work is also inspired by multi-hop strategy used in \textbf{Memory Networks (MemNets)} \cite{DBLP:conf/nips/SukhbaatarSWF15}. The iterative reasoning idea is also used in \textbf{Reinforced Mnemonic Reader} \cite{DBLP:conf/ijcai/HuPHQW018} and \textbf{ReasoNet} \cite{DBLP:conf/kdd/ShenHGC17}, as both are trained with reinforcement learning, but the latter can dynamically determine whether to continue the comprehension process or not. Our work also relates to multi-step QA models \cite{DBLP:journals/corr/SordoniBB16,DBLP:conf/acl/MinZZH19}. %Other related work includes \textbf{r-net} \cite{DBLP:conf/acl/WangYWCZ17}, \textbf{DCN} \cite{DBLP:conf/iclr/XiongZS17}, Document Reader \cite{DBLP:conf/acl/ChenFWB17}, \textbf{Interactive AoA Reader} \cite{DBLP:conf/acl/CuiCWWLH17}, and \textbf{Multi-layer Embedding with Memory Network (MEMEN)} \cite{DBLP:journals/corr/PanLZCCH17}.  %https://arxiv.org/abs/1705.02798 reinforcement learning
%(\newcite{DBLP:conf/nips/HermannKGEKSB15,DBLP:conf/asru/FengXGWZ15, DBLP:journals/corr/TanXZ15,DBLP:conf/emnlp/LiLJH15,DBLP:conf/acl/TanSXZ16, DBLP:conf/kdd/ShenHGC17,DBLP:journals/corr/YuHBP14,DBLP:journals/corr/abs-1804-09541}). 
%For example, in (\newcite{DBLP:conf/nips/HermannKGEKSB15,DBLP:journals/corr/abs-1804-09541}), attention based DNN models are used to achieve fast machine comprehension on several QA datasets. In (\newcite{DBLP:journals/corr/YuHBP14,DBLP:conf/asru/FengXGWZ15}), researchers employ convolutional neural network (CNN) based models to tackle general QA tasks. (\newcite{DBLP:conf/acl/TanSXZ16}) shows that how an LSTM DNN structure can be used on QA tasks. Some of the end-to-end models also leverage reinforcement learning based structures in RC tasks \cite{DBLP:conf/kdd/ShenHGC17,DBLP:conf/ijcai/HuPHQW018}. \kechen{add multi-step}
%In (\newcite{DBLP:conf/kdd/ShenHGC17}), the authors proposed an RL based model, named as ReasoNets, that can dynamically decide whether to continue or stop reading during inference in RC tasks. 
%The authors of (\newcite{DBLP:conf/aaai/KhashabiKSR18}) introduce a graph-based system, which translates the reasoning process into a search for an optimal sub-graph satisfying certain constraints.

%. For example, as in \newcite{DBLP:conf/aaai/KhashabiKSR18}, a graph-based system is designed to encode multiple pre-trained semantic abstractions for reasoning purpose, where they translate a question answering (QA) reasoning procedure into a search for an optimal subgraph that satisﬁes certain global and local properties. They also claim that instead of using an end-to-end model which can learn "everything" from a very large dataset, their models can extract a sufficiently complete linguistic abstraction of the text that allows answering different types of questions.

%\kechen{We need a paragraph here to briefly introduce related work on End-to-end models for reading comprehension based question answering tasks. Deep reinforcement learning models in QA. Reasoning in QA (For reasoning, you can use these two references: \newcite{DBLP:conf/kdd/ShenHGC17} propose ReasoNets, a reinforcement based model, that dynamically decide whether to continue or to terminate the inference process in machine comprehension tasks. \newcite{DBLP:conf/aaai/KhashabiKSR18} design a graph-based system to encode the pre-trained NLP information. They claim Departing from the currently popular paradigm of generating a very large dataset and learning “everything” from it in an end-to-end fashion, we argue—and demonstrate via our QA system—that one can successfully leverage pre-trained NLP modules to extract a sufficiently complete linguistic abstraction of the text that allows answering interesting questions about it). }

% Some  models also further leverage a (co-)attention structure to deal with the long term interactions between questions and documents , such that they can deal with large scale datasets including unstructured documents(XXX). These models generated extremely good results in terms of answer accuracy and F1 scores. 


%\subsection{Usage of discourse markers}
%Discourse structure describes the high-level organization of a text. 
%Another line of work that relates to ours is discourse analysis. Discourse markers can be effectively applied to discover discourse structure, and thus play an important role in a number of high-impact applications %\cite{DBLP:journals/corr/cs-CL-0006023,DBLP:conf/naacl/JiHE16,DBLP:conf/acl/QinWK17}. %, such as text summarization \cite{DBLP:conf/acl/QinWK17}, recognizing dialogue acts or social acts %of adjacent utterances from phone conversations 
%\cite{DBLP:journals/corr/cs-CL-0006023,DBLP:conf/naacl/JiHE16}, and automatic evaluation of argument corpora \cite{DBLP:journals/dad/BursteinTC13,DBLP:journals/tacl/WangBSQ17}.  
%Specifically, \cite{DBLP:conf/sigir/PragerBCR00} explores the usage of a single discourse marker (e.g.``by") to answer ``How"-type questions, which is one of the earliest work on leveraging discourse markers to tackle question answering tasks. Following this direction, \cite{DBLP:conf/acl/JansenSC14} experiments with discourse markers and deep representations to answer ``How"- and ``Why"- questions. %There are also many systems built for reading comprehension tasks by considering the discourse markers or cue phrases \cite{DBLP:journals/ir/VerberneHTRB11,DBLP:conf/acl/OhTHSSO13}. 
%Other relevant studies explore discourse relation in QA tasks \cite{DBLP:journals/tal/VerberneBCO06,DBLP:journals/ir/VerberneHTRB11,DBLP:conf/acl/NarasimhanB15}. %For example, in \newcite{DBLP:journals/tal/VerberneBCO06}, it argues that an RST relation holds between a (satellite) text span representing a question topic and a (nucleus) text span representing the answer.
%In terms of the RST model, a rhetorical relation typically holds between two EDUs, one of which (the nucleus) is more essential for the writer’s intention than the other (the satellite).
%Answering how questions using a single discourse marker, by, was previously explored by Prager et al. (2000), who searched for by followed by a present participle (e.g. by *ing) to elevate answer candidates in a ranking framework. Verberne et al. (2011) extracted 47 cue phrases such as because from a small collection of web documents, and used the cosine similarity between an answer candidate and a bag of words containing these cue phrases as a single feature in their reranking model for non-factoid why QA. Extending this, Oh et al. (2013) built a classifier to identify causal relations using a small set of cue phrases (e.g., because and is caused by). This classifier was then used to extract instances of causal relations in answer candidates, which were turned into features in a reranking model for Japanense why QA